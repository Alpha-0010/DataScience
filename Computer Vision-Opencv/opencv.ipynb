{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59c1a4f4",
   "metadata": {},
   "source": [
    "# Opencv\n",
    "    - a library commonly used for Computer Vision Tasks..\n",
    "    - Can be used for Image Processing..\n",
    "    - Used for image Manipulation[Sharpen the image around corners ,etc..]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "210d66f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e7754ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We used image manipulation in matplotlib but opencv is widely used for this specific task only. And has lot of\n",
    "# methods to support image manipulation. opencv can also be used to detect faces.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b479c78",
   "metadata": {},
   "source": [
    "### Read and Display Images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a1ff2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same read function as matplotlib...\n",
    "img_cv2=cv2.imread(\"./dog.jpg\")\n",
    "img_plt=plt.imread(\"./dog.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57cb300e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(img_cv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e63666",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "070f362d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2820, 3760, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_cv2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbc1691a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "# If we read image using opencv the channels are BGR not RGB like in matplotlib..\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ee42ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.namedWindow(\"output\", cv2.WINDOW_AUTOSIZE)\n",
    "imS = cv2.resize(img_cv2, (960, 540))\n",
    "cv2.imshow(\"Dog Image\",imS)\n",
    "cv2.waitKey(5000)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d04c2",
   "metadata": {},
   "source": [
    "## Changing color space "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0caa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the opencv color space from BGR to some other color space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36ab4057",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb=cv2.cvtColor(img_cv2,cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e6d2a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2820, 3760, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0d4a2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16247a4c",
   "metadata": {},
   "source": [
    "## Image Resizing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af60826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2820, 3760, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a29262e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the image to fit in the frame...\n",
    "img_new=cv2.resize(img_rgb,(500,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2dea64db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 500, 3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef6d3a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_new)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e16034b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: reshape in numpy is not same as resize in opencv. We cannot reshape a 4*5 matrix into 5*5 matrix because the number\n",
    "# of elements are different in both the matrices. But we can resize it into 5*5. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550a401a",
   "metadata": {},
   "source": [
    "### blur "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0037a308",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_blur=cv2.blur(img_new,(10,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01d06649",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_blur)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b430a85",
   "metadata": {},
   "source": [
    "## Image Rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c01f8388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2820, 3760, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_rgb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2be4b690",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows,cols=img_rgb.shape[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3908cc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Try to rotate the Image around the center pixel 20 degree in the Anticlockwise direction..\n",
    "M=cv2.getRotationMatrix2D((rows/2,cols/2),20,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d371daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply Rotation Matrix 'M' to the original Image.\n",
    "I=cv2.warpAffine(img_rgb,M,(cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c4b1d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447d9e1a",
   "metadata": {},
   "source": [
    "## Image Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1af2814f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Create a Translation Matrix then apply this translation Matrix to our original Matrix.\n",
    "# [1,0,50] ---> 1: Along X-Axis, 0: No Ratation, 50: Shift 50px along X-Axis.\n",
    "# [0,1,20] ---> 0: No Rotation, 1: Along Y-Axis, 20: Shift 20px along Y-Axis.\n",
    "M=np.float32(([1,0,150],[0,1,200]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a894f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply this Translation Matrix to our Image Matrix.\n",
    "I=cv2.warpAffine(img_rgb,M,(cols,rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f05b65fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(I)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534b1c2",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "    - There are many Edge Detection Algorithms but we will use: Canny Edge Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26633240",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=cv2.Canny(img_rgb,45,45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60736282",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6786f5",
   "metadata": {},
   "source": [
    "## Read Video from Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d426ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video is nothing but multiple frames per second. So video is nothing but images. So, basically using the webcam\n",
    "# we can capture frames.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "170ec21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8a467a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3b2650a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign cam to the Primary webcam that's why 0. If we wish to use an external webcam then replace that 0 with 1..\n",
    "cam=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "99fdc000",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    # cam.read() returns two values one is the Frame and the other is ret which will be True or False depending\n",
    "    # upon if the webcam is able to capture image..\n",
    "    # Capture Frame-By-Frame...\n",
    "    ret, frame=cam.read()\n",
    "    \n",
    "    if ret==False:\n",
    "        continue\n",
    "    \n",
    "    # Display the resulting Frame..\n",
    "    cv2.imshow('My Frame',frame)\n",
    "    \n",
    "    # To stop the webcam if 'q' key is pressed..\n",
    "    keyPressed=cv2.waitKey(1) & 0xFF\n",
    "    if keyPressed== ord('q'):\n",
    "        break\n",
    "    \n",
    "\n",
    "# When everything is done release the capture and destroyAllWindows..\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b6f0a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cc88e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cfaafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
